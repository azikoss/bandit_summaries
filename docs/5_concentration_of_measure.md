# 5. Concentration of Measure
 Let's recall that the optimal action is the action with the largest mean. Since pay-offs are initially unknown, we must learn them from data. This chapter introduces essential theory that explains how long it takes to learn the reward means, and how to estimate the upper bound of the mean rewards. The introduced concepts are essential to design and understand many bandit algorithms. 
 
# Tail Probabilities
Tail probability is a function of a random variable <img src="https://render.githubusercontent.com/render/math?math=X"> and a certain threshold <img src="https://render.githubusercontent.com/render/math?math=\epsilon > 0"> that expresses the probability of <img src="https://render.githubusercontent.com/render/math?math=X"> being greater or smaller than <img src="https://render.githubusercontent.com/render/math?math=\epsilon">.  
 
 We can apply this concept to express how much the sampling reward mean <img src="https://render.githubusercontent.com/render/math?math=\hat{\mu}"> over/under-estimates the true reward mean <img src="https://render.githubusercontent.com/render/math?math=\mu">.  This is formally called a tail probability of <img src="https://render.githubusercontent.com/render/math?math=\hat{\mu} - \mu"> and can be expressed as <img src="https://render.githubusercontent.com/render/math?math=\mathbb{P}(\hat{\mu} \geq \mu \%2B \epsilon)"> and <img src="https://render.githubusercontent.com/render/math?math=\mathbb{P}(\hat{\mu} \leq \mu - \epsilon)">. The first expression is called upper tail probability and the second lower tail probability. 
               
For instance, let <img src="https://render.githubusercontent.com/render/math?math=X ~ \N(\mu,\sigma)"> and <img src="https://render.githubusercontent.com/render/math?math=\epsilon = 2\sigma">, given the z-table, the upper tail probability of <img src="https://render.githubusercontent.com/render/math?math=\mathbb{P}(\hat{\mu} \geq \mu %2B 2\sigma)=2.3\%25">. 

*TODO: an illustration??*
 
One could think why not to use variance to express the spread of the sample mean <img src="https://render.githubusercontent.com/render/math?math=\hat{\mu}">. Variance of <img src="https://render.githubusercontent.com/render/math?math=\hat{\mu}"> is defined as <img src="https://render.githubusercontent.com/render/math?math=\mathbb{V}[\hat{\mu}] = \mathbb{E}[(\hat{\mu} - \mu)^2] =\dfrac{\sigma^2}{n}"> ([proof](https://youtu.be/7mYDHbrLEQo)). The problem is that variance only quantifies that the squared distance between <img src="https://render.githubusercontent.com/render/math?math=\hat{\mu}"> and <img src="https://render.githubusercontent.com/render/math?math=\mu"> and does not tell much about the distribution of the error between the sample and the true mean. If we would continue with the above example and say that we would pull an arm <img src="https://render.githubusercontent.com/render/math?math=n=100"> times, then <img src="https://render.githubusercontent.com/render/math?math=\mathbb{V}[\hat{\mu}] = \dfrac{\sigma^2}{100}">. This expression does not tell anything about the distribution of the distance between <img src="https://render.githubusercontent.com/render/math?math=\hat{\mu}"> and <img src="https://render.githubusercontent.com/render/math?math=\mu"> (we cannot say that the distance is with certain probability less than <img src="https://render.githubusercontent.com/render/math?math=\epsilon"> just like the tail probability function does).
 

# The Inequalities of Markov and Chebyshev
In the above example, we calculated the tail-probability by using z-table. In practice, we will not have such a comfort to work with normal distribution only. Thus, we introduce two most common inequalities that will help us to bound *any* random variable <img src="https://render.githubusercontent.com/render/math?math=X">  
1. Markov: <img src="https://render.githubusercontent.com/render/math?math=\mathbb{P}(X \geq \epsilon) \leq \dfrac{\mathbb{E}[X]}{\epsilon}">     
1. Chebyshev: <img src="https://render.githubusercontent.com/render/math?math=\mathbb{P}(|X - \mathbb{E}[X]| \geq \epsilon) \leq \dfrac{\mathbb{V}[X]}{\epsilon^2}">

Let's illustrate how both inequalities work in practice. We can make an example from any context, since <img src="https://render.githubusercontent.com/render/math?math=X"> can be *any* random variable. Let <img src="https://render.githubusercontent.com/render/math?math=X"> represent an outcome of a dice. The dice does not have to be fair, but for sake of this exercise let's say it is so <img src="https://render.githubusercontent.com/render/math?math=\mathbb{E}[X]=3.5">. Let's find out what is the probability that <img src="https://render.githubusercontent.com/render/math?math=X"> is at least <img src="https://render.githubusercontent.com/render/math?math=\epsilon=6">. Using the Markov inequality, <img src="https://render.githubusercontent.com/render/math?math=\mathbb{P}(X \geq 6) \leq \dfrac{3.5}{6} = 58.3\%25">. Thus, the probability of throwing 6 (and more) is at most 58.3%. As illustrated on this example, the Markov's inequality is quite loose since the chance of throwing 6 on a fair dice is only 16.6%. To be exact, we bounded the probability of throwing *at least* six. Since the [proof](https://www.quora.com/What-is-an-intuitive-explanation-of-Markovs-inequality) of the Markos inequality stem's solely from the behavior of <img src="https://render.githubusercontent.com/render/math?math=X"> around its mean, it does not matter how many faces would the dice have and the estimate of 58.3% would still hold.  
 
To illustrate the Chebyshev inequality, we have to know the variance of <img src="https://render.githubusercontent.com/render/math?math=X">. The variance of a fair dice is 105/36~2.91. Let's bound the same event as above and express what is the  maximum probability of throwing at least 6. Given that the Chebyshev inequality bounds the distance in between <img src="https://render.githubusercontent.com/render/math?math=X"> and its expected value, we need to set <img src="https://render.githubusercontent.com/render/math?math=\epsilon=6-3.5=2.5"> to bound the probability of throwing (at least) 2.5 units from the expected value of 3.5; so essentially throwing 3.5+-2.5 which is equivalent to throwing 1 or 6. Using the Chebyshev inequality, <img src="https://render.githubusercontent.com/render/math?math=\mathbb{P}(|X - 3.5| \geq 2.5) \leq \dfrac{2.91}{2.5^2} = 46.6\%25">. Thus, the probability that the distance of <img src="https://render.githubusercontent.com/render/math?math=X"> from its mean is larger than 2.5 (outcomes 1 and 6 on a dice) is at most 46.6%. The bound is again quite loose as the probability of throwing 1 or 6 is 16.6%+16.6% = 33.2%.

 
We can use Chebyshev inequality and bound the sample reward mean <img src="https://render.githubusercontent.com/render/math?math=\hat{\mu}"> (with variance <img src="https://render.githubusercontent.com/render/math?math=\mathbb{V}[\hat{\mu}] =\dfrac{\sigma^2}{n}">) as <img src="https://render.githubusercontent.com/render/math?math=\mathbb{P}(|\hat{\mu} - \mu| \geq \epsilon) \leq \dfrac{\sigma^2}{n\epsilon^2}">. This result is great because it does not rely no any assumption and can be used in any context. On the other hand, as we saw above, the Chebyshev inequality can be quite loose. For that reason, we introduce subgaussian random variables and given their properties present tighter bounds.  


# Subgaussian Random Variables
 A random variable <img src="https://render.githubusercontent.com/render/math?math=X"> is <img src="https://render.githubusercontent.com/render/math?math=\sigma">-subgaussian if it holds that <img src="https://render.githubusercontent.com/render/math?math=\mathbb{E}[e^{\lambda X}] \leq e^{\lambda^2 \sigma^2 / 2}"> for all <img src="https://render.githubusercontent.com/render/math?math=\lambda \in \mathbb{R}">. This says that <img src="https://render.githubusercontent.com/render/math?math=X"> is a <img src="https://render.githubusercontent.com/render/math?math=\sigma">-subgaussian if the Laplace transform of <img src="https://render.githubusercontent.com/render/math?math=X"> is dominated by the Laplace transform of a Gaussian random variable with mean zero and variance <img src="https://render.githubusercontent.com/render/math?math=\sigma^2"> [[ref](http://www.stat.cmu.edu/~arinaldo/36788/subgaussians.pdf)]. The consequence of this is that subgaussian random variables are centered (<img src="https://render.githubusercontent.com/render/math?math=\mathbb{E}[X]=0">) and their variance is given by the subgaussian parameter. We say that the random variables that are not centered are <img src="https://render.githubusercontent.com/render/math?math=\sigma">-subgaussian if the noise <img src="https://render.githubusercontent.com/render/math?math=X-\mathbb{E}[X]"> is <img src="https://render.githubusercontent.com/render/math?math=\sigma">-subgaussian. Subgaussians have much lighter tails than Guassians (they decay at least as fast as the Gaussians) [[ref](https://statisfaction.wordpress.com/2017/05/02/sub-gaussian-property-for-the-beta-distribution-part-1/)] and they are more uniformly distributed around the mean than the Gaussians [[ref](https://www.researchgate.net/figure/Examples-of-Gaussian-supergaussian-and-subgaussian-distributions-All-distributions_fig3_228661138)]. 

A natural example of a subgaussian random variable is a centered Gaussian. If <img src="https://render.githubusercontent.com/render/math?math=N(0, \sigma^2)">, then <img src="https://render.githubusercontent.com/render/math?math=\mathbb{E}[e^{\lambda X}] = e^{\sigma^2 \lambda^2 / 2}"> ([calculation](https://ocw.mit.edu/courses/mathematics/18-s997-high-dimensional-statistics-spring-2015/lecture-notes/MIT18_S997S15_Chapter1.pdf)) which is equal to the right-hand side of the definition of subgaussianity above and thus center Gaussian is a subgaussian random variable for all <img src="https://render.githubusercontent.com/render/math?math=\sigma">. 


Furthermore, 
 * if <img src="https://render.githubusercontent.com/render/math?math=|X| \leq B"> almost surely for <img src="https://render.githubusercontent.com/render/math?math=B \geq 0">, then <img src="https://render.githubusercontent.com/render/math?math=X"> is <img src="https://render.githubusercontent.com/render/math?math=B">-subgaussian
 * If <img src="https://render.githubusercontent.com/render/math?math=X \in [a,b]"> almost surely, then <img src="https://render.githubusercontent.com/render/math?math=X"> is <img src="https://render.githubusercontent.com/render/math?math=(b-a)/2">-subgaussian (so Bernoulli distribution is 1/2-subgaussian).    
 
# The Cramér-Chernoff Method
Now, we present a theorem based on which we can bound the reward. If <img src="https://render.githubusercontent.com/render/math?math=x"> is <img src="https://render.githubusercontent.com/render/math?math=\sigma">-subgaussian, the, for any <img src="https://render.githubusercontent.com/render/math?math=\epsilon \geq 0">, <img src="https://render.githubusercontent.com/render/math?math=\mathbb{P}(X \geq \epsilon) \leq \exp(-\frac{\epsilon ^ 2}{2\sigma^2})">. The proof, which follows the  **Cremér-Chernoff method** goes as follow. Let <img src="https://render.githubusercontent.com/render/math?math=\lambda > 0"> be a constant to be tuned later. Then,
1. <img src="https://render.githubusercontent.com/render/math?math=\mathbb{P}(X \geq \epsilon) = \mathbb{P}(\exp(\lambda X) \geq \exp(\lambda \epsilon))"> // the whole formula was exponentiated to the power of <img src="https://render.githubusercontent.com/render/math?math=\exp(\lambda)">
1. <img src="https://render.githubusercontent.com/render/math?math=\leq \mathbb{E}[\exp(\lambda X)] \exp(-\lambda \epsilon)"> // Markov's inequality was used
1. <img src="https://render.githubusercontent.com/render/math?math=\leq \exp(\frac{\lambda^2 \sigma^2)}{2} \exp(-\lambda\epsilon)"> // The definition of subgaussianity was used
1. <img src="https://render.githubusercontent.com/render/math?math=\= \exp(\frac{\lambda^2 \sigma^2)}{2}-\lambda\epsilon)">
1. <img src="https://render.githubusercontent.com/render/math?math=\= \exp(-\frac{\epsilon^2}{2 \sigma^2})"> // by choosing <img src="https://render.githubusercontent.com/render/math?math=\lambda"> to be <img src="https://render.githubusercontent.com/render/math?math=\frac{\epsilon}{\sigma^2}">

By setting the right hand side of the equation <img src="https://render.githubusercontent.com/render/math?math=\exp(-\frac{\epsilon^2}{2\sigma^2})"> to <img src="https://render.githubusercontent.com/render/math?math=\delta"> and solving this equaition for <img src="https://render.githubusercontent.com/render/math?math=\epsilon"> and making the corresponding substitutions, we get an equivalent form of the above formula is <img src="https://render.githubusercontent.com/render/math?math=\mathbb{P}(X \geq \sqrt{2\sigma^2\log(1/\delta)}) \leq \delta">. This is a more convenient because we can easily set the probability <img src="https://render.githubusercontent.com/render/math?math=\delta"> that <img src="https://render.githubusercontent.com/render/math?math=\X"> will be higher than <img src="https://render.githubusercontent.com/render/math?math=\sqrt{2\sigma^2\log(1/\delta)})">. A similar inequality holds for the left tail.

 
Let's focus on bounding the tail behavior of <img src="https://render.githubusercontent.com/render/math?math=\hat{\mu} - \mu">. For that, two more properties of the subgaussians random variables need to be introduced. Let <img src="https://render.githubusercontent.com/render/math?math=X"> be <img src="https://render.githubusercontent.com/render/math?math=\sigma">-subgaussian and <img src="https://render.githubusercontent.com/render/math?math=X_1"> and <img src="https://render.githubusercontent.com/render/math?math=X_2"> be independent and <img src="https://render.githubusercontent.com/render/math?math=\sigma_1"> and <img src="https://render.githubusercontent.com/render/math?math=\sigma_2">-subgaussian, respectively, then
1. <img src="https://render.githubusercontent.com/render/math?math=cX"> is <img src="https://render.githubusercontent.com/render/math?math=|c|\sigma">-subgaussian for all <img src="https://render.githubusercontent.com/render/math?math=c \in \mathbb{R}"> 
1. <img src="https://render.githubusercontent.com/render/math?math=X_1 \%2B X_2"> is <img src="https://render.githubusercontent.com/render/math?math=\sqrt{\sigma_1^2 \%2B \sigma_2^2}">-subgaussian 


Presuming that <img src="https://render.githubusercontent.com/render/math?math=X_i - \mu"> are independent, <img src="https://render.githubusercontent.com/render/math?math=\sigma">-subgaussian random variable, then for any <img src="https://render.githubusercontent.com/render/math?math=\epsilon \geq 0">, <img src="https://render.githubusercontent.com/render/math?math=\mathbb{P}(\hat{\mu} - \mu \geq \epsilon) \leq \exp(-\frac{n\epsilon^2}{2\sigma^2})">, where <img src="https://render.githubusercontent.com/render/math?math=\hat{\mu} = \frac{1}{n}\sum_{t=1}^{n} X_t">. 

To proof this. By the properties introduced in the previous paragraph, it holds that <img src="https://render.githubusercontent.com/render/math?math=\hat{\mu} - \mu = \sum_{t=1}^{n} (X_i - \mu)/n"> is <img src="https://render.githubusercontent.com/render/math?math=\sigma/\sqrt{n}">-subgaussian as each element in the sum is <img src="https://render.githubusercontent.com/render/math?math=\sigma^2/n^2">-subgaussian, and the sum of <img src="https://render.githubusercontent.com/render/math?math=n"> such subgaussian is <img src="https://render.githubusercontent.com/render/math?math=\sqrt{n \frac{\sigma^2}{n^2}} = \sigma/\sqrt{n}">-subgaussian. Given this and using the theorem on bounding the subgaussian random variable (choosing <img src="https://render.githubusercontent.com/render/math?math=\lambda=\frac{\epsilon n}{\sigma^2}">) finilizes the proof. 

The above inequality present a stronger bound that the one obtained from Chebyshev's inequality expect when <img src="https://render.githubusercontent.com/render/math?math=\epsilon"> is very small.

Similarly, the inequality can be rewritten as <img src="https://render.githubusercontent.com/render/math?math=\mathbb{P}(\hat{\mu} \geq \mu \%2B \sqrt{\frac{2\sigma^2\log(1/\delta)}{n}}) \leq \delta">.





# References
This text *my* summary from the 5. Chapter of [Bandit Algorithm](https://tor-lattimore.com/downloads/book/book.pdf) book. The summary contains copy&pasted text from the book as well as some additional text. 
